# -*- coding: utf-8 -*-
"""cluster_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10tPu6MINVKKwoOAGyBkQcA3lX4HKQ8Sq

Cluster Analysis: DBSCAN (1) and Naive Bayes (2) Classification:

How to use this notebook: 
1. If not pulled from GitHub with data, upload your DBSCAN dataset (dbscan_11 - data.csv) named as "data.csv", and both Naive Bayes datasets (naive_bayes_11 - test.csv and train) as test_data.csv and train_data.csv.
2. As we have not yet implemented type conversion yet, edit your Naive Bayes datasets in the following schema:
conical 0, spherical 1, bell 2
close 0, distant 1, none 2
yes 1, no 0
edible 1, poisonous 0
3. If not installed, get the following packages (pandas and sklearn)
$pip install pandas
$pip install scikit-learn
$pip install seaborn
$pip install matplotlib
$pip install collections
Now you can run the code
"""

import pandas as pd
from sklearn.cluster import DBSCAN
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
# Read the dataset
df = pd.read_csv("data.csv")
df.head()

# define cluster function with epsilon=0,8 and min points = 3 as provided in Homework Assignment
# fit the data 
cluster = DBSCAN(eps=0.8,min_samples=3).fit(df)
# create array to store lbels
label_array = cluster.labels_
# set the labels
set(cluster.labels_)

Counter(cluster.labels_)

# Plot the the final results 
p = sns.scatterplot(data=df, x="x", y="y", hue=cluster.labels_, legend="full", palette="deep")
sns.move_legend(p, "upper right", bbox_to_anchor=(1.17, 1.2), title='Clusters found for Exercise 1:')
plt.show()

# Naive Bayes Implementation Strategy:
# We try to use the train dataset to split into x, y train and x,y test and 
# make predictions on the test data set
# note: Test dataset provided is more a cross validation set, not a test set,
# as we normally use test sets to validate our prredictions - but not having target class provided makes it impossible to score accuracy
df_test = pd.read_csv("test_data.csv")
df_train = pd.read_csv("train_data.csv")


#y = df_train.pop("cap_shape")
df_train.head()

# Make copy to not manipulate original dataframe
dfc = df_train.copy()
# Pop out prediction feature y from dataframe
y = dfc.pop("target_class")
x = df_train.drop("target_class", axis=1)
x.head()
#y.head()

X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=9) #Split the dataset


nv = GaussianNB() # create a classifier
nv.fit(X_train,y_train) # fitting the data


y_pred = nv.predict(X_test) # store the prediction data
accuracy_score(y_test,y_pred) # calculate the accuracy
#print(y_pred)

df_test.head()

prediction = nv.predict(df_test)
print("these are the predictions for both test cases respectively:" , prediction , "0 means poisonous, 1 means edible")